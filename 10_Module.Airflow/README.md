Задание:

В качестве источника данных у нас имеется файл «olympics.csv», который содержит статистику по олимпийским играм. Необходимо подготовить ETL процесс построения витрины данных, которая будет содержать список, показывающий число всех медалей, выигранных каждой страной в течение всей истории олимпийских игр. Для каждой страны, необходимо показать год первой и последней заработанной медали.



В качестве источника необходимо взять файл «olympics.csv», приложенный к заданию.
Необходимо создать в папке «dags» папку «input» и скопировать в нее файл «olympics.csv».
Создать даг «extract_raw_olympics», который будет копировать данные из файла в базу «bi_rd_lab_db» в таблицу «raw.olympics».
Примечание: Для чтения данных из CSV файла можно воспользоваться функцией ‘read_csv‘ из библиотеки ‘pandas‘ (LINK). Для записи данных в базу рекомендуется использовать ‘PostgresHook‘ (LINK).

В базе «bi_rd_lab_db» создать таблицу «dds.olympics», содержащую поля «country», «first_medal_date», «last_medal_date», «count_of_medals».
В базе «bi_rd_lab_db» создать процедуру в схеме «etl» - «etl.usp_dds_olympics_insert». На первом шаге процедуры таблица «dds.olympics» должна полностью очищаться. На втором шаге – заполняться агрегированными данными из таблицы «raw.olympics». Таблица «dds.olympics» будет содержать список, показывающий число всех медалей, выигранных каждой страной в течение всей истории олимпийских игр. Для каждой страны, необходимо показать год первой и последней заработанной медали.
Создать даг «process_dds», который будет вызывать процедуру «etl.usp_dds_olympics_insert».
Примечание: Для запуска postgres процедуры из Airflow можно воспользоваться «PostgresOperator», передавая в параметр «sql» вызов хранимой процедуры, например, таким образом: «sql=f"call etl.usp_dds_olympics_insert();"».

Создать представление (view) «dm.olympics», в которой будут отображаться данные из таблицы «dds.olympics».